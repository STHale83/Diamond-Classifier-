{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF =pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>337</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Fair</td>\n",
       "      <td>E</td>\n",
       "      <td>VS2</td>\n",
       "      <td>65.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>337</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>338</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat        cut color clarity  depth  table  price     x  \\\n",
       "0           1   0.23      Ideal     E     SI2   61.5   55.0    326  3.95   \n",
       "1           2   0.21    Premium     E     SI1   59.8   61.0    326  3.89   \n",
       "2           3   0.23       Good     E     VS1   56.9   65.0    327  4.05   \n",
       "3           4   0.29    Premium     I     VS2   62.4   58.0    334  4.20   \n",
       "4           5   0.31       Good     J     SI2   63.3   58.0    335  4.34   \n",
       "5           6   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94   \n",
       "6           7   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95   \n",
       "7           8   0.26  Very Good     H     SI1   61.9   55.0    337  4.07   \n",
       "8           9   0.22       Fair     E     VS2   65.1   61.0    337  3.87   \n",
       "9          10   0.23  Very Good     H     VS1   59.4   61.0    338  4.00   \n",
       "\n",
       "      y     z  \n",
       "0  3.98  2.43  \n",
       "1  3.84  2.31  \n",
       "2  4.07  2.31  \n",
       "3  4.23  2.63  \n",
       "4  4.35  2.75  \n",
       "5  3.96  2.48  \n",
       "6  3.98  2.47  \n",
       "7  4.11  2.53  \n",
       "8  3.78  2.49  \n",
       "9  4.05  2.39  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head(10) #To drop the first column, its sasme as the ID, its not relevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.26</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>337</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.22</td>\n",
       "      <td>Fair</td>\n",
       "      <td>E</td>\n",
       "      <td>VS2</td>\n",
       "      <td>65.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>337</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>338</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n",
       "6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n",
       "7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n",
       "8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n",
       "9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To rename column x as length, column y as width, column z as depth\n",
    "#but there is a depth column which is supposed to be Depth Percentage\n",
    "DF.rename(columns = {'x':'length', 'y':'width', \n",
    "                              'depth':'depthPect'}, inplace = True)\n",
    "DF.rename(columns = {'z':'depth'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.26</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>337</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.22</td>\n",
       "      <td>Fair</td>\n",
       "      <td>E</td>\n",
       "      <td>VS2</td>\n",
       "      <td>65.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>337</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>338</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depthPect  table  price  length  width  \\\n",
       "0   0.23      Ideal     E     SI2       61.5   55.0    326    3.95   3.98   \n",
       "1   0.21    Premium     E     SI1       59.8   61.0    326    3.89   3.84   \n",
       "2   0.23       Good     E     VS1       56.9   65.0    327    4.05   4.07   \n",
       "3   0.29    Premium     I     VS2       62.4   58.0    334    4.20   4.23   \n",
       "4   0.31       Good     J     SI2       63.3   58.0    335    4.34   4.35   \n",
       "5   0.24  Very Good     J    VVS2       62.8   57.0    336    3.94   3.96   \n",
       "6   0.24  Very Good     I    VVS1       62.3   57.0    336    3.95   3.98   \n",
       "7   0.26  Very Good     H     SI1       61.9   55.0    337    4.07   4.11   \n",
       "8   0.22       Fair     E     VS2       65.1   61.0    337    3.87   3.78   \n",
       "9   0.23  Very Good     H     VS1       59.4   61.0    338    4.00   4.05   \n",
       "\n",
       "   depth  \n",
       "0   2.43  \n",
       "1   2.31  \n",
       "2   2.31  \n",
       "3   2.63  \n",
       "4   2.75  \n",
       "5   2.48  \n",
       "6   2.47  \n",
       "7   2.53  \n",
       "8   2.49  \n",
       "9   2.39  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>62.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.26</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>61.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>337</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>65.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>337</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>59.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>338</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut  color  clarity  depthPect  table  price  length  width  depth\n",
       "0   0.23    5      6        2       61.5   55.0    326    3.95   3.98   2.43\n",
       "1   0.21    4      6        3       59.8   61.0    326    3.89   3.84   2.31\n",
       "2   0.23    2      6        5       56.9   65.0    327    4.05   4.07   2.31\n",
       "3   0.29    4      2        4       62.4   58.0    334    4.20   4.23   2.63\n",
       "4   0.31    2      1        2       63.3   58.0    335    4.34   4.35   2.75\n",
       "5   0.24    3      1        6       62.8   57.0    336    3.94   3.96   2.48\n",
       "6   0.24    3      2        7       62.3   57.0    336    3.95   3.98   2.47\n",
       "7   0.26    3      3        3       61.9   55.0    337    4.07   4.11   2.53\n",
       "8   0.22    1      6        4       65.1   61.0    337    3.87   3.78   2.49\n",
       "9   0.23    3      3        5       59.4   61.0    338    4.00   4.05   2.39"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To change the categorical variables into ordinal, cut, color and clarity\n",
    "#Cut: quality of the cut (Fair(1), Good(2), Very Good(3), Premium(4), Ideal(5))\n",
    "DF.loc[DF['cut'] =='Ideal','cut'] = 5 # replace Ideal in cut as 5\n",
    "DF.loc[DF['cut'] =='Premium','cut'] = 4 # replace Premium in cut as 4\n",
    "DF.loc[DF['cut'] =='Very Good','cut'] = 3 # replace Very Good in cut as 3\n",
    "DF.loc[DF['cut'] =='Good','cut'] = 2 # replace Good in cut as 2\n",
    "DF.loc[DF['cut'] =='Fair','cut'] = 1 # replace Fair in cut as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color: diamond color, from J (worst) to D (best) D(7), E(6), F(5), G(4), H(3), I(2), J(1) \n",
    "DF.loc[DF['color'] =='D','color'] = 7# replace D in color as 7\n",
    "DF.loc[DF['color'] =='E','color'] = 6# replace E in color as 6\n",
    "DF.loc[DF['color'] =='F','color'] = 5# replace F in color as 5\n",
    "DF.loc[DF['color'] =='G','color'] = 4# replace G in color as 4\n",
    "DF.loc[DF['color'] =='H','color'] = 3# replace H in color as 3\n",
    "DF.loc[DF['color'] =='I','color'] = 2# replace I in color as 2\n",
    "DF.loc[DF['color'] =='J','color'] = 1# replace J in color as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1,IF (best))\n",
    "#I1 (1), SI2(2), SI1(3), VS2(4), VS1(5), VVS2(6), VVS1(7),IF ((8)\n",
    "DF.loc[DF['clarity'] =='I1','clarity'] = 1# replace I1 in clarity as 1\n",
    "DF.loc[DF['clarity'] =='SI2','clarity'] = 2# replace SI2 in clarity as 2\n",
    "DF.loc[DF['clarity'] =='SI1','clarity'] = 3# replace SI1 in clarity as 3\n",
    "DF.loc[DF['clarity'] =='VS2','clarity'] = 4# replace VS2 in clarity as 4\n",
    "DF.loc[DF['clarity'] =='VS1','clarity'] = 5# replace VS1 in clarity as 5\n",
    "DF.loc[DF['clarity'] =='VVS2','clarity'] = 6# replace VVS2 in clarity as 6\n",
    "DF.loc[DF['clarity'] =='VVS1','clarity'] = 7# replace VVS1in clarity as 7\n",
    "DF.loc[DF['clarity'] =='IF','clarity'] = 8# replace IF in clarity as 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>3.904097</td>\n",
       "      <td>4.405803</td>\n",
       "      <td>4.051020</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.116600</td>\n",
       "      <td>1.701105</td>\n",
       "      <td>1.647136</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat           cut         color       clarity     depthPect  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940      3.904097      4.405803      4.051020     61.749405   \n",
       "std        0.474011      1.116600      1.701105      1.647136      1.432621   \n",
       "min        0.200000      1.000000      1.000000      1.000000     43.000000   \n",
       "25%        0.400000      3.000000      3.000000      3.000000     61.000000   \n",
       "50%        0.700000      4.000000      4.000000      4.000000     61.800000   \n",
       "75%        1.040000      5.000000      6.000000      5.000000     62.500000   \n",
       "max        5.010000      5.000000      7.000000      8.000000     79.000000   \n",
       "\n",
       "              table         price        length         width         depth  \n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000  \n",
       "mean      57.457184   3932.799722      5.731157      5.734526      3.538734  \n",
       "std        2.234491   3989.439738      1.121761      1.142135      0.705699  \n",
       "min       43.000000    326.000000      0.000000      0.000000      0.000000  \n",
       "25%       56.000000    950.000000      4.710000      4.720000      2.910000  \n",
       "50%       57.000000   2401.000000      5.700000      5.710000      3.530000  \n",
       "75%       59.000000   5324.250000      6.540000      6.540000      4.040000  \n",
       "max       95.000000  18823.000000     10.740000     58.900000     31.800000  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe(include = \"all\")\n",
    "#it looks like there is no missing values in the dataset\n",
    "#price and PricePerCarat are way larger over other variables, normalization is needed in this case\n",
    "#However, min of length, width and depth is 0, which is not supposed to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#dig more into the cases where 0 length, width and depth\n",
    "print(len(DF[DF['length'] == 0]))\n",
    "print(len(DF[DF['width'] == 0]))\n",
    "print(len(DF[DF['depth'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Because the dimension of the size need to be precise here, cannot replace it with the mean of the variables\n",
    "#also we have a large dataset, and there are only a few cases of where length, width and depth are 0\n",
    "#I decide to just remove those records\n",
    "DF = DF.drop(DF[DF['length'] == 0].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "      <td>53932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797879</td>\n",
       "      <td>3.904194</td>\n",
       "      <td>4.405789</td>\n",
       "      <td>4.051101</td>\n",
       "      <td>61.749336</td>\n",
       "      <td>57.457029</td>\n",
       "      <td>3932.136079</td>\n",
       "      <td>5.732007</td>\n",
       "      <td>5.735254</td>\n",
       "      <td>3.539259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473986</td>\n",
       "      <td>1.116526</td>\n",
       "      <td>1.701165</td>\n",
       "      <td>1.647109</td>\n",
       "      <td>1.432514</td>\n",
       "      <td>2.234064</td>\n",
       "      <td>3988.734835</td>\n",
       "      <td>1.119670</td>\n",
       "      <td>1.140343</td>\n",
       "      <td>0.704434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>949.750000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat           cut         color       clarity     depthPect  \\\n",
       "count  53932.000000  53932.000000  53932.000000  53932.000000  53932.000000   \n",
       "mean       0.797879      3.904194      4.405789      4.051101     61.749336   \n",
       "std        0.473986      1.116526      1.701165      1.647109      1.432514   \n",
       "min        0.200000      1.000000      1.000000      1.000000     43.000000   \n",
       "25%        0.400000      3.000000      3.000000      3.000000     61.000000   \n",
       "50%        0.700000      4.000000      4.000000      4.000000     61.800000   \n",
       "75%        1.040000      5.000000      6.000000      5.000000     62.500000   \n",
       "max        5.010000      5.000000      7.000000      8.000000     79.000000   \n",
       "\n",
       "              table         price        length         width         depth  \n",
       "count  53932.000000  53932.000000  53932.000000  53932.000000  53932.000000  \n",
       "mean      57.457029   3932.136079      5.732007      5.735254      3.539259  \n",
       "std        2.234064   3988.734835      1.119670      1.140343      0.704434  \n",
       "min       43.000000    326.000000      3.730000      3.680000      0.000000  \n",
       "25%       56.000000    949.750000      4.710000      4.720000      2.910000  \n",
       "50%       57.000000   2401.000000      5.700000      5.710000      3.530000  \n",
       "75%       59.000000   5324.000000      6.540000      6.540000      4.040000  \n",
       "max       95.000000  18823.000000     10.740000     58.900000     31.800000  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe(include = \"all\") #now we still have some cases where depth is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.drop(DF[DF['depth'] == 0].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "      <td>53920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797698</td>\n",
       "      <td>3.904228</td>\n",
       "      <td>4.405972</td>\n",
       "      <td>4.051502</td>\n",
       "      <td>61.749514</td>\n",
       "      <td>57.456834</td>\n",
       "      <td>3930.993231</td>\n",
       "      <td>5.731627</td>\n",
       "      <td>5.734887</td>\n",
       "      <td>3.540046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473795</td>\n",
       "      <td>1.116579</td>\n",
       "      <td>1.701272</td>\n",
       "      <td>1.647005</td>\n",
       "      <td>1.432331</td>\n",
       "      <td>2.234064</td>\n",
       "      <td>3987.280446</td>\n",
       "      <td>1.119423</td>\n",
       "      <td>1.140126</td>\n",
       "      <td>0.702530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5323.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat           cut         color       clarity     depthPect  \\\n",
       "count  53920.000000  53920.000000  53920.000000  53920.000000  53920.000000   \n",
       "mean       0.797698      3.904228      4.405972      4.051502     61.749514   \n",
       "std        0.473795      1.116579      1.701272      1.647005      1.432331   \n",
       "min        0.200000      1.000000      1.000000      1.000000     43.000000   \n",
       "25%        0.400000      3.000000      3.000000      3.000000     61.000000   \n",
       "50%        0.700000      4.000000      4.000000      4.000000     61.800000   \n",
       "75%        1.040000      5.000000      6.000000      5.000000     62.500000   \n",
       "max        5.010000      5.000000      7.000000      8.000000     79.000000   \n",
       "\n",
       "              table         price        length         width         depth  \n",
       "count  53920.000000  53920.000000  53920.000000  53920.000000  53920.000000  \n",
       "mean      57.456834   3930.993231      5.731627      5.734887      3.540046  \n",
       "std        2.234064   3987.280446      1.119423      1.140126      0.702530  \n",
       "min       43.000000    326.000000      3.730000      3.680000      1.070000  \n",
       "25%       56.000000    949.000000      4.710000      4.720000      2.910000  \n",
       "50%       57.000000   2401.000000      5.700000      5.710000      3.530000  \n",
       "75%       59.000000   5323.250000      6.540000      6.540000      4.040000  \n",
       "max       95.000000  18823.000000     10.740000     58.900000     31.800000  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe(include = \"all\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depthPect</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.134953</td>\n",
       "      <td>-0.291360</td>\n",
       "      <td>-0.352757</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>0.181646</td>\n",
       "      <td>0.921592</td>\n",
       "      <td>0.977779</td>\n",
       "      <td>0.953991</td>\n",
       "      <td>0.961048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>-0.134953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.189153</td>\n",
       "      <td>-0.218073</td>\n",
       "      <td>-0.433306</td>\n",
       "      <td>-0.053491</td>\n",
       "      <td>-0.126232</td>\n",
       "      <td>-0.122181</td>\n",
       "      <td>-0.150647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>-0.291360</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025783</td>\n",
       "      <td>-0.047373</td>\n",
       "      <td>-0.026481</td>\n",
       "      <td>-0.172431</td>\n",
       "      <td>-0.270671</td>\n",
       "      <td>-0.263915</td>\n",
       "      <td>-0.270011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity</th>\n",
       "      <td>-0.352757</td>\n",
       "      <td>0.189153</td>\n",
       "      <td>-0.025783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067457</td>\n",
       "      <td>-0.160256</td>\n",
       "      <td>-0.146789</td>\n",
       "      <td>-0.372865</td>\n",
       "      <td>-0.359015</td>\n",
       "      <td>-0.370250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depthPect</th>\n",
       "      <td>0.028259</td>\n",
       "      <td>-0.218073</td>\n",
       "      <td>-0.047373</td>\n",
       "      <td>-0.067457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.295733</td>\n",
       "      <td>-0.010729</td>\n",
       "      <td>-0.025017</td>\n",
       "      <td>-0.029069</td>\n",
       "      <td>0.095023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>0.181646</td>\n",
       "      <td>-0.433306</td>\n",
       "      <td>-0.026481</td>\n",
       "      <td>-0.160256</td>\n",
       "      <td>-0.295733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.196097</td>\n",
       "      <td>0.184493</td>\n",
       "      <td>0.152483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.921592</td>\n",
       "      <td>-0.053491</td>\n",
       "      <td>-0.172431</td>\n",
       "      <td>-0.146789</td>\n",
       "      <td>-0.010729</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887231</td>\n",
       "      <td>0.867864</td>\n",
       "      <td>0.868206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>0.977779</td>\n",
       "      <td>-0.126232</td>\n",
       "      <td>-0.270671</td>\n",
       "      <td>-0.372865</td>\n",
       "      <td>-0.025017</td>\n",
       "      <td>0.196097</td>\n",
       "      <td>0.887231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974918</td>\n",
       "      <td>0.975435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>0.953991</td>\n",
       "      <td>-0.122181</td>\n",
       "      <td>-0.263915</td>\n",
       "      <td>-0.359015</td>\n",
       "      <td>-0.029069</td>\n",
       "      <td>0.184493</td>\n",
       "      <td>0.867864</td>\n",
       "      <td>0.974918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>0.961048</td>\n",
       "      <td>-0.150647</td>\n",
       "      <td>-0.270011</td>\n",
       "      <td>-0.370250</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.152483</td>\n",
       "      <td>0.868206</td>\n",
       "      <td>0.975435</td>\n",
       "      <td>0.956744</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat       cut     color   clarity  depthPect     table  \\\n",
       "carat      1.000000 -0.134953 -0.291360 -0.352757   0.028259  0.181646   \n",
       "cut       -0.134953  1.000000  0.020517  0.189153  -0.218073 -0.433306   \n",
       "color     -0.291360  0.020517  1.000000 -0.025783  -0.047373 -0.026481   \n",
       "clarity   -0.352757  0.189153 -0.025783  1.000000  -0.067457 -0.160256   \n",
       "depthPect  0.028259 -0.218073 -0.047373 -0.067457   1.000000 -0.295733   \n",
       "table      0.181646 -0.433306 -0.026481 -0.160256  -0.295733  1.000000   \n",
       "price      0.921592 -0.053491 -0.172431 -0.146789  -0.010729  0.127245   \n",
       "length     0.977779 -0.126232 -0.270671 -0.372865  -0.025017  0.196097   \n",
       "width      0.953991 -0.122181 -0.263915 -0.359015  -0.029069  0.184493   \n",
       "depth      0.961048 -0.150647 -0.270011 -0.370250   0.095023  0.152483   \n",
       "\n",
       "              price    length     width     depth  \n",
       "carat      0.921592  0.977779  0.953991  0.961048  \n",
       "cut       -0.053491 -0.126232 -0.122181 -0.150647  \n",
       "color     -0.172431 -0.270671 -0.263915 -0.270011  \n",
       "clarity   -0.146789 -0.372865 -0.359015 -0.370250  \n",
       "depthPect -0.010729 -0.025017 -0.029069  0.095023  \n",
       "table      0.127245  0.196097  0.184493  0.152483  \n",
       "price      1.000000  0.887231  0.867864  0.868206  \n",
       "length     0.887231  1.000000  0.974918  0.975435  \n",
       "width      0.867864  0.974918  1.000000  0.956744  \n",
       "depth      0.868206  0.975435  0.956744  1.000000  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carat seems to be correlated to many other vairables, that makes sense, the larger of the diamond, \n",
    "#the larger its length, width, depth and price.\n",
    "#cut is moderately correlated to the depth Pect and table\n",
    "#color is moderately correlated to length, width and depth\n",
    "#clarity is moderately correlated to length, width and depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised learning\n",
    "#Try to classify the cut, color and clarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut\n",
    "cut_x=DF[['carat','color','clarity','depthPect','table','price','length','width','depth']]\n",
    "cut_y=DF['cut']\n",
    "cut_x=np.array(cut_x)\n",
    "cut_y=np.array(cut_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing #normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler().fit(cut_x)\n",
    "cut_x = min_max_scaler.transform(cut_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors #Use Knn as classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43136, 9)\n",
      "(10784, 9)\n",
      "(43136,)\n",
      "(10784,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #split 20% as testing, 80% as training\n",
    "Xcut_train,Xcut_test, ycut_train, ycut_test = train_test_split(cut_x, cut_y, test_size=0.2, random_state=33)\n",
    "\n",
    "print (Xcut_train.shape)\n",
    "print (Xcut_test.shape)\n",
    "print (ycut_train.shape)\n",
    "print (ycut_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best K for KNN\n",
    "lstWeight=[]\n",
    "for i in range(1,21):\n",
    "    knnclf = neighbors.KNeighborsClassifier(i, weights='distance')\n",
    "    knnclf.fit(Xcut_train, ycut_train)\n",
    "    knnpreds_test = knnclf.predict(Xcut_test)\n",
    "    lstWeight.append(knnclf.score(Xcut_test, ycut_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658290059347181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(lstWeight))\n",
    "lstWeight.index(max(lstWeight)) #K = 12 can give us the optimal performance of KNN to classify the cut with 65.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#color  do the same thing as above for color classification\n",
    "color_x=DF[['carat','cut','clarity','depthPect','table','price','length','width','depth']]\n",
    "color_y=DF['color']\n",
    "color_x=np.array(color_x)\n",
    "color_y=np.array(color_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler().fit(color_x)\n",
    "color_x = min_max_scaler.transform(color_x)\n",
    "Xcolor_train,Xcolor_test, ycolor_train, ycolor_test = train_test_split(color_x, color_y, test_size=0.2, random_state=33)\n",
    "lstWeight=[]\n",
    "lstWeight=[]\n",
    "for i in range(1,21):\n",
    "    knnclf = neighbors.KNeighborsClassifier(i, weights='distance')\n",
    "    knnclf.fit(Xcolor_train, ycolor_train)\n",
    "    knnpreds_test = knnclf.predict(Xcolor_test)\n",
    "    lstWeight.append(knnclf.score(Xcolor_test, ycolor_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4092173590504451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(lstWeight))\n",
    "lstWeight.index(max(lstWeight))    #K = 7 can give us the optimal performance of KNN to classify the color with 40.92%, which is not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clarity do the same thing as above for calarity classification\n",
    "clarity_x=DF[['carat','cut','color','depthPect','table','price','length','width','depth']]\n",
    "clarity_y=DF['clarity']\n",
    "clarity_x=np.array(clarity_x)\n",
    "clarity_y=np.array(clarity_y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(clarity_x)\n",
    "clarity_x = min_max_scaler.transform(clarity_x)\n",
    "Xclarity_train,Xclarity_test, yclarity_train, yclarity_test = train_test_split(clarity_x, clarity_y, test_size=0.2, random_state=33)\n",
    "lstWeight=[]\n",
    "lstWeight=[]\n",
    "for i in range(1,21):\n",
    "    knnclf = neighbors.KNeighborsClassifier(i, weights='distance')\n",
    "    knnclf.fit(Xclarity_train, yclarity_train)\n",
    "    knnpreds_test = knnclf.predict(Xclarity_test)\n",
    "    lstWeight.append(knnclf.score(Xclarity_test, yclarity_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5239243323442137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(lstWeight))\n",
    "lstWeight.index(max(lstWeight)) #K = 9 can give us the optimal performance of KNN to classify clarity with 52.39%, which is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall, KNN method can give us acceptable/moderate classifcaiton performance on Cut, color and clarity\n",
    "#but how about Decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57452725, 0.3795661 , 0.28931751, 0.19899852, 0.13649852,\n",
       "       0.14855341, 0.20715875, 0.29970326, 0.53218327, 0.40742115])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cut Decision tree crossvalidation 10\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "treeclf = tree.DecisionTreeClassifier(criterion='entropy',min_samples_split=3)\n",
    "cv_scores = model_selection.cross_val_score(treeclf, cut_x, cut_y, cv=10)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy on X-Val: 0.32 (+/- 0.29)\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) # Overall Accuracy is only 32% which is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy on X-Val: 0.11 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "#color Decision tree crossvalidation 10\n",
    "treeclf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "cv_scores = model_selection.cross_val_score(treeclf, color_x, color_y, cv=10)\n",
    "cv_scores\n",
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) #11% overall Accuracy is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy on X-Val: 0.12 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "#calarity Decision tree crossvalidation 10\n",
    "treeclf = tree.DecisionTreeClassifier(criterion='entropy',min_samples_split=3)\n",
    "cv_scores = model_selection.cross_val_score(treeclf, clarity_x, clarity_y, cv=10)\n",
    "cv_scores\n",
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) #12% overall Accuracy is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree on classifying cut, color and clarity is not good\n",
    "#then How about LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62921765 0.61301687 0.61257418 0.60181751 0.61721068 0.56750742\n",
      " 0.55545252 0.55489614 0.60063068 0.61317254]\n",
      "Overall Accuracy on X-Val: 0.60 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "#cut LDA\n",
    "ldclf = LinearDiscriminantAnalysis()\n",
    "cv_scores = model_selection.cross_val_score(ldclf, cut_x, cut_y, cv=10)\n",
    "print(cv_scores)\n",
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) #Overall Accuracy 60% on cut is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2300278  0.23229514 0.29718205 0.33722655 0.3264095  0.25723294\n",
      " 0.25018546 0.23242441 0.25463994 0.22902747]\n",
      "Overall Accuracy on X-Val: 0.26 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "#color LDA\n",
    "ldclf = LinearDiscriminantAnalysis()\n",
    "cv_scores = model_selection.cross_val_score(ldclf, color_x, color_y, cv=10)\n",
    "print(cv_scores)\n",
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) #Overall Accuracy 31% on cut is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37386469 0.48378128 0.46227989 0.48146088 0.3722181  0.39788536\n",
      " 0.29313544 0.37810761 0.38801262 0.38819818]\n",
      "Overall Accuracy on X-Val: 0.40 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "#clarity LDA\n",
    "ldclf = LinearDiscriminantAnalysis()\n",
    "cv_scores = model_selection.cross_val_score(ldclf, clarity_x, clarity_y, cv=10)\n",
    "print(cv_scores)\n",
    "print(\"Overall Accuracy on X-Val: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2)) #Overall Accuracy 40% on cut is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compared the performance of KNN, Decision tree and LDA, KNN is the best supervised method to classify the color, cut and clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unsupervised method Kmeans\n",
    "from sklearn.cluster import KMeans \n",
    "import importlib\n",
    "import kMeans\n",
    "\n",
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kMeans' from 'C:\\\\Users\\\\Hale\\\\Desktop\\\\dsc478\\\\final project\\\\kMeans.py'>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(kMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before doing Kmeans clustering, get rid of some not related variables first like Price\n",
    "#cut Kmeans\n",
    "Kmeancut_x=DF[['carat','color','clarity','depthPect','table','length','width','depth']]\n",
    "Kmeancut_y=DF['cut']\n",
    "Kmeancut_x=np.array(Kmeancut_x)\n",
    "Kmeancut_y=np.array(Kmeancut_y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(Kmeancut_x)\n",
    "Kmeancut_x = min_max_scaler.transform(Kmeancut_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015157147795881431\n"
     ]
    }
   ],
   "source": [
    "#cut 5 values\n",
    "centroids, clusters = kMeans.kMeans(Kmeancut_x, 5, kMeans.distEclud, kMeans.randCent)\n",
    "\n",
    "print (completeness_score(Kmeancut_y,clusters[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014826399985036364\n"
     ]
    }
   ],
   "source": [
    "print (homogeneity_score(Kmeancut_y,clusters[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024274230929518942\n",
      "0.020522676509247717\n"
     ]
    }
   ],
   "source": [
    "#color Kmeans 7 classess\n",
    "Kmeancolor_x=DF[['carat','cut','clarity','depthPect','table','length','width','depth']]\n",
    "Kmeancolor_y=DF['color']\n",
    "Kmeancolor_x=np.array(Kmeancolor_x)\n",
    "Kmeancolor_y=np.array(Kmeancolor_y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(Kmeancolor_x)\n",
    "Kmeancolor_x = min_max_scaler.transform(Kmeancolor_x)\n",
    "centroids, clusters = kMeans.kMeans(Kmeancolor_x, 7, kMeans.distEclud, kMeans.randCent)\n",
    "\n",
    "print (completeness_score(Kmeancolor_y,clusters[:,0]))\n",
    "print (homogeneity_score(Kmeancolor_y,clusters[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027803504383363112\n",
      "0.02381579986323319\n"
     ]
    }
   ],
   "source": [
    "#clarity Kmeans 8 classes\n",
    "Kmeanclarity_x=DF[['carat','cut','color','depthPect','table','length','width','depth']]\n",
    "Kmeanclarity_y=DF['clarity']\n",
    "Kmeanclarity_x=np.array(Kmeanclarity_x)\n",
    "Kmeanclarity_y=np.array(Kmeanclarity_y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(Kmeanclarity_x)\n",
    "Kmeanclarity_x = min_max_scaler.transform(Kmeanclarity_x)\n",
    "centroids, clusters = kMeans.kMeans(Kmeanclarity_x, 8, kMeans.distEclud, kMeans.randCent)\n",
    "\n",
    "print (completeness_score(Kmeanclarity_y,clusters[:,0]))\n",
    "print (homogeneity_score(Kmeanclarity_y,clusters[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model to Predict the Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depthPect', 'table', 'price',\n",
       "       'length', 'width', 'depth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression for 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DF[['carat', 'cut', 'color', 'clarity', 'depthPect', 'table',\n",
    "       'length', 'width', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=DF['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y= np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10784, 9)\n",
      "(43136, 9)\n",
      "(43136,)\n",
      "(10784,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201.831919029932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute RMSE on training data\n",
    "p = linreg.predict(X_train)\n",
    "\n",
    "# Now we can constuct a vector of errors\n",
    "err = abs(p-y_train)\n",
    "total_error = np.dot(err,err)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Coefficients: \n",
      " [10976.44784555   122.3326683    320.84578343   494.98887833\n",
      "   -80.08777516   -26.00650268  -939.514467      39.8175227\n",
      "   -88.29307445]\n"
     ]
    }
   ],
   "source": [
    "print ('Regression Coefficients: \\n', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now let's compute RMSE using 10-fold x-validation\n",
    "n = 10\n",
    "#kf = KFold(len(x),n_splits=n)\n",
    "\n",
    "kf = KFold(n_splits=n)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "KFold(n_splits=n,random_state=None, shuffle=False)\n",
    " \n",
    "\n",
    "xval_err = 0\n",
    "#or train,test in kf:\n",
    "for train, test in kf.split(X):\n",
    "    linreg.fit(X[train],y[train])\n",
    "    p = linreg.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(X[test]))\n",
    "       \n",
    "rmse_10cv = xval_err/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "RMSE on training: 1201.8319\n",
      "RMSE on 10-fold CV: 1214.0642\n"
     ]
    }
   ],
   "source": [
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE  on 10-fold CV is slightly higher than that on training\n",
    "#Lets see if regularized method will improve the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8508168367622053\n",
      "6 0.8508168367622053\n",
      "11 0.8508168367622053\n",
      "16 0.8553886020755034\n",
      "21 0.8553886020755034\n",
      "26 0.850679240324166\n",
      "31 0.850679240324166\n",
      "36 0.850679240324166\n",
      "41 0.8488545031883368\n",
      "46 0.8488545031883368\n",
      "51 0.8604834922579645\n",
      "56 0.8604834922579645\n",
      "61 0.8604834922579645\n",
      "66 0.9032323667399039\n",
      "71 0.9032323667399039\n",
      "76 0.902065841301624\n",
      "81 0.902065841301624\n",
      "86 0.902065841301624\n",
      "91 0.9047001319412089\n",
      "96 0.9047001319412089\n",
      "18\n",
      "Optimal percentile of features:91 \n",
      "\n",
      "Optimal number of features:8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = DF[['carat','color','clarity','depthPect','table','price','length','width','depth']]\n",
    "target = DF['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=33)\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "linreg = LinearRegression()\n",
    "\n",
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "    scores = model_selection.cross_val_score(linreg, X_train_fs, y_train, cv=5)\n",
    "    print (i,scores.mean())\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentile = np.where(results == results.max())[0]\n",
    "print(optimal_percentile[0])\n",
    "print (\"Optimal percentile of features:{0}\".format(percentiles[optimal_percentile[0]]), \"\\n\")\n",
    "optimal_num_features = int(percentiles[optimal_percentile[0]]*len(features.columns)/100)\n",
    "print (\"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat \t 246169.8073494757\n",
      "color \t 1423.4716354083816\n",
      "clarity \t 978.6033915337107\n",
      "depthPect \t 7.118562768719305\n",
      "table \t 720.7642730499787\n",
      "length \t 160432.5819277144\n",
      "width \t 126146.7580059612\n",
      "depth \t 128506.35247289916\n"
     ]
    }
   ],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=91) #we got opitmal percentile is 91 above\n",
    "X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "\n",
    "for i in range(len(features.columns.values)):\n",
    "    if fs.get_support()[i]:\n",
    "        print (features.columns.values[i],'\\t', fs.scores_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best model is without Depth Percentage variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Method: Simple Linear Regression\n",
      "RMSE on training: 1204.9955\n",
      "RMSE on 10-fold CV: 1224.6207\n"
     ]
    }
   ],
   "source": [
    "#use the selected model above for linear regression and see if there is improvement\n",
    "X = DF[['carat', 'cut', 'color', 'clarity','table',\n",
    "       'length', 'width', 'depth']]\n",
    "y=DF['price']\n",
    "X = np.array(X)\n",
    "y= np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "p = linreg.predict(X_train)\n",
    "err = abs(p-y_train)\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "# Now let's compute RMSE using 10-fold x-validation\n",
    "n = 10\n",
    "#kf = KFold(len(x),n_splits=n)\n",
    "\n",
    "kf = KFold(n_splits=n)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)  \n",
    "KFold(n_splits=n,random_state=None, shuffle=False)\n",
    " \n",
    "\n",
    "xval_err = 0\n",
    "#or train,test in kf:\n",
    "for train, test in kf.split(X):\n",
    "    linreg.fit(X[train],y[train])\n",
    "    p = linreg.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(X[test]))\n",
    "       \n",
    "rmse_10cv = xval_err/n\n",
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression for price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridgeparameter(data,target):\n",
    "\n",
    "    print('Ridge Regression')\n",
    "    print('alpha\\t RMSE_train\\t RMSE_10cv\\n')\n",
    "    alpha = np.linspace(.01,20,50)\n",
    "    t_rmse = np.array([])\n",
    "    cv_rmse = np.array([])\n",
    "    X = np.array(data)\n",
    "    y = np.array(target)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "    for a in alpha:\n",
    "        ridge = Ridge(alpha=a)\n",
    "\n",
    "        # computing the RMSE on training data\n",
    "        ridge.fit(X_train,y_train)\n",
    "        p = ridge.predict(X_train)\n",
    "        err = p-y_train\n",
    "        total_error = np.dot(err,err)\n",
    "        rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "        kf.get_n_splits(X_train)\n",
    "\n",
    "        KFold(n_splits=5,random_state=None, shuffle=False)\n",
    "        # computing RMSE using 10-fold cross validation\n",
    "        #kf = KFold(len(x), n_folds=10)\n",
    "        xval_err = 0\n",
    "        for train, test in kf.split(X_train):\n",
    "            ridge.fit(X_train[train], y_train[train])\n",
    "            p = ridge.predict(X_train[test])\n",
    "            err = p - y_train[test]\n",
    "            xval_err += np.sqrt(np.dot(err,err)/len(X_train[test]))\n",
    "        rmse_10cv = xval_err/n\n",
    "    \n",
    "        t_rmse = np.append(t_rmse, [rmse_train])\n",
    "        cv_rmse = np.append(cv_rmse, [rmse_10cv])\n",
    "        print('{}\\t {}\\t\\t {}'.format(a,rmse_train,rmse_10cv))\n",
    "    plt.plot(alpha, t_rmse, label='RMSE-Train')\n",
    "    plt.plot(alpha, cv_rmse, label='RMSE_XVal')\n",
    "    plt.legend( ('RMSE-Train', 'RMSE_XVal') )\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = DF[['carat','color','clarity','depthPect','table','price','length','width','depth']]\n",
    "target = DF['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "alpha\t RMSE_train\t RMSE_10cv\n",
      "\n",
      "0.01\t 5.445487018997123e-10\t\t 6.079122938078849e-10\n",
      "0.41795918367346935\t 7.726691612025151e-09\t\t 5.075641499211472e-09\n",
      "0.8259183673469387\t 1.553774648437802e-08\t\t 9.984889437699538e-09\n",
      "1.233877551020408\t 2.3337707069729942e-08\t\t 1.491060844153268e-08\n",
      "1.6418367346938774\t 3.113151033030782e-08\t\t 1.9837745444944998e-08\n",
      "2.0497959183673466\t 3.8909790535417826e-08\t\t 2.4757099310714892e-08\n",
      "2.457755102040816\t 4.66776461184626e-08\t\t 2.966102426198768e-08\n",
      "2.865714285714285\t 5.4434110116802904e-08\t\t 3.455380979357915e-08\n",
      "3.2736734693877545\t 6.218022730810994e-08\t\t 3.944419358400605e-08\n",
      "3.681632653061224\t 6.991618615829979e-08\t\t 4.431140436323306e-08\n",
      "4.0895918367346935\t 7.763588014713077e-08\t\t 4.918143624776849e-08\n",
      "4.497551020408163\t 8.534567382614431e-08\t\t 5.403361094359573e-08\n",
      "4.905510204081632\t 9.304498277689455e-08\t\t 5.887314697371321e-08\n",
      "5.313469387755101\t 1.0073281924721304e-07\t\t 6.370677839645026e-08\n",
      "5.721428571428571\t 1.0840906694225209e-07\t\t 6.852703251666214e-08\n",
      "6.12938775510204\t 1.1607460504848758e-07\t\t 7.333530298028216e-08\n",
      "6.537346938775509\t 1.2372878009490494e-07\t\t 7.81361402911646e-08\n",
      "6.9453061224489785\t 1.3137364756500656e-07\t\t 8.292967214518281e-08\n",
      "7.353265306122448\t 1.3900617305707767e-07\t\t 8.770532128130332e-08\n",
      "7.761224489795917\t 1.4662426287024602e-07\t\t 9.247910059383819e-08\n",
      "8.169183673469387\t 1.5423763913724543e-07\t\t 9.724080087397681e-08\n",
      "8.577142857142857\t 1.6183764580737585e-07\t\t 1.0199195318178046e-07\n",
      "8.985102040816326\t 1.6942392264756138e-07\t\t 1.0673600419454948e-07\n",
      "9.393061224489795\t 1.7700523397382673e-07\t\t 1.114720784829001e-07\n",
      "9.801020408163264\t 1.845697273834801e-07\t\t 1.1619569389471954e-07\n",
      "10.208979591836734\t 1.9213056361930437e-07\t\t 1.209097255788577e-07\n",
      "10.616938775510203\t 1.996751124739833e-07\t\t 1.2561813684811937e-07\n",
      "11.024897959183672\t 2.0721123169711784e-07\t\t 1.3031334233264446e-07\n",
      "11.432857142857141\t 2.1474025954267592e-07\t\t 1.3500157147500987e-07\n",
      "11.84081632653061\t 2.2225735963068237e-07\t\t 1.3968556034797796e-07\n",
      "12.24877551020408\t 2.2976082206486978e-07\t\t 1.4435576689133219e-07\n",
      "12.65673469387755\t 2.3725988847650226e-07\t\t 1.490211762908349e-07\n",
      "13.064693877551019\t 2.44744413259647e-07\t\t 1.5367259775228596e-07\n",
      "13.472653061224488\t 2.5222074655941526e-07\t\t 1.5832507037586333e-07\n",
      "13.880612244897957\t 2.59690360388312e-07\t\t 1.6296417025548434e-07\n",
      "14.288571428571426\t 2.671446776968716e-07\t\t 1.6759282321878126e-07\n",
      "14.696530612244896\t 2.7459216104262966e-07\t\t 1.722183003498197e-07\n",
      "15.104489795918365\t 2.8203031320472587e-07\t\t 1.7683289232214543e-07\n",
      "15.512448979591834\t 2.894605461610865e-07\t\t 1.8144048146491943e-07\n",
      "15.920408163265304\t 2.968796089566651e-07\t\t 1.8604233673190496e-07\n",
      "16.328367346938776\t 3.04288736895375e-07\t\t 1.90632901672432e-07\n",
      "16.736326530612246\t 3.11690225526304e-07\t\t 1.9521905762080328e-07\n",
      "17.144285714285715\t 3.1908014584743324e-07\t\t 1.9979861575855486e-07\n",
      "17.552244897959184\t 3.2646252276264286e-07\t\t 2.0436945158718208e-07\n",
      "17.960204081632654\t 3.338322233701723e-07\t\t 2.0893192676374068e-07\n",
      "18.368163265306123\t 3.411959367552946e-07\t\t 2.13486628023901e-07\n",
      "18.776122448979592\t 3.4855023593490874e-07\t\t 2.1803524822746062e-07\n",
      "19.18408163265306\t 3.5589880005136174e-07\t\t 2.2257822147997549e-07\n",
      "19.59204081632653\t 3.6323243745567684e-07\t\t 2.271152877141972e-07\n",
      "20.0\t 3.705652251697196e-07\t\t 2.3164181399908737e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ridgeparameter(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train data aside 1205.021385404552\n",
      "RMSE on test data aside 1267.3877557493242\n"
     ]
    }
   ],
   "source": [
    "#seems alpha = 0.01 works the best in this case\n",
    "ridge = Ridge(alpha=3)\n",
    "ridge.fit(X_train,y_train)\n",
    "p = ridge.predict(X_train)\n",
    "err = p-y_train\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "p = ridge.predict(X_test)\n",
    "err = p-y_test\n",
    "total_error = np.dot(err,err)\n",
    "rmse_test = np.sqrt(total_error/len(p))\n",
    "print (\"RMSE on train data aside {}\".format(rmse_train))\n",
    "print (\"RMSE on test data aside {}\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "def Lassoparameter(data,target):\n",
    "\n",
    "    print('Lasso Regression')\n",
    "    print('alpha\\t RMSE_train\\t RMSE_10cv\\n')\n",
    "    alpha = np.linspace(.01,50,50)\n",
    "    t_rmse = np.array([])\n",
    "    cv_rmse = np.array([])\n",
    "    X = np.array(data)\n",
    "    y = np.array(target)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "    for a in alpha:\n",
    "        lasso = Lasso(alpha=a)\n",
    "\n",
    "        # computing the RMSE on training data\n",
    "        lasso.fit(X_train,y_train)\n",
    "        p = lasso.predict(X_train)\n",
    "        err = p-y_train\n",
    "        total_error = np.dot(err,err)\n",
    "        rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "        kf.get_n_splits(X_train)\n",
    "\n",
    "        KFold(n_splits=5,random_state=None, shuffle=False)\n",
    "        # computing RMSE using 10-fold cross validation\n",
    "        #kf = KFold(len(x), n_folds=10)\n",
    "        xval_err = 0\n",
    "        for train, test in kf.split(X_train):\n",
    "            lasso.fit(X_train[train], y_train[train])\n",
    "            p = lasso.predict(X_train[test])\n",
    "            err = p - y_train[test]\n",
    "            xval_err += np.sqrt(np.dot(err,err)/len(X_train[test]))\n",
    "        rmse_10cv = xval_err/n\n",
    "    \n",
    "        t_rmse = np.append(t_rmse, [rmse_train])\n",
    "        cv_rmse = np.append(cv_rmse, [rmse_10cv])\n",
    "        print('{:.3f}\\t {:.4f}\\t\\t {:.4f}'.format(a,rmse_train,rmse_10cv))\n",
    "    plt.plot(alpha, t_rmse, label='RMSE-Train')\n",
    "    plt.plot(alpha, cv_rmse, label='RMSE_XVal')\n",
    "    plt.legend( ('RMSE-Train', 'RMSE_XVal') )\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression\n",
      "alpha\t RMSE_train\t RMSE_10cv\n",
      "\n",
      "0.010\t 0.0000\t\t 0.0000\n",
      "1.030\t 0.0003\t\t 0.0001\n",
      "2.050\t 0.0005\t\t 0.0003\n",
      "3.071\t 0.0008\t\t 0.0004\n",
      "4.091\t 0.0010\t\t 0.0005\n",
      "5.111\t 0.0013\t\t 0.0006\n",
      "6.131\t 0.0015\t\t 0.0008\n",
      "7.151\t 0.0018\t\t 0.0009\n",
      "8.172\t 0.0021\t\t 0.0010\n",
      "9.192\t 0.0023\t\t 0.0012\n",
      "10.212\t 0.0026\t\t 0.0013\n",
      "11.232\t 0.0028\t\t 0.0014\n",
      "12.252\t 0.0031\t\t 0.0015\n",
      "13.273\t 0.0033\t\t 0.0017\n",
      "14.293\t 0.0036\t\t 0.0018\n",
      "15.313\t 0.0039\t\t 0.0019\n",
      "16.333\t 0.0041\t\t 0.0021\n",
      "17.353\t 0.0044\t\t 0.0022\n",
      "18.374\t 0.0046\t\t 0.0023\n",
      "19.394\t 0.0049\t\t 0.0024\n",
      "20.414\t 0.0051\t\t 0.0026\n",
      "21.434\t 0.0054\t\t 0.0027\n",
      "22.454\t 0.0057\t\t 0.0028\n",
      "23.475\t 0.0059\t\t 0.0030\n",
      "24.495\t 0.0062\t\t 0.0031\n",
      "25.515\t 0.0064\t\t 0.0032\n",
      "26.535\t 0.0067\t\t 0.0033\n",
      "27.556\t 0.0069\t\t 0.0035\n",
      "28.576\t 0.0072\t\t 0.0036\n",
      "29.596\t 0.0074\t\t 0.0037\n",
      "30.616\t 0.0077\t\t 0.0039\n",
      "31.636\t 0.0080\t\t 0.0040\n",
      "32.657\t 0.0082\t\t 0.0041\n",
      "33.677\t 0.0085\t\t 0.0042\n",
      "34.697\t 0.0087\t\t 0.0044\n",
      "35.717\t 0.0090\t\t 0.0045\n",
      "36.737\t 0.0092\t\t 0.0046\n",
      "37.758\t 0.0095\t\t 0.0048\n",
      "38.778\t 0.0098\t\t 0.0049\n",
      "39.798\t 0.0100\t\t 0.0050\n",
      "40.818\t 0.0103\t\t 0.0051\n",
      "41.838\t 0.0105\t\t 0.0053\n",
      "42.859\t 0.0108\t\t 0.0054\n",
      "43.879\t 0.0110\t\t 0.0055\n",
      "44.899\t 0.0113\t\t 0.0057\n",
      "45.919\t 0.0116\t\t 0.0058\n",
      "46.939\t 0.0118\t\t 0.0059\n",
      "47.960\t 0.0121\t\t 0.0060\n",
      "48.980\t 0.0123\t\t 0.0062\n",
      "50.000\t 0.0126\t\t 0.0063\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4VVXWwOHfIoVQA4SeEBIglNAhdLEgTUVQYQZwxsEy4qjo6DcqoDJiHXtninXUcQYVUKIizYqKSFBIB0IIEDoJhJae9f1xLhAxECC5ucm9630eHu45Z99z1wkhK3vvc9YWVcUYY4w5V7U8HYAxxpiazRKJMcaYCrFEYowxpkIskRhjjKkQSyTGGGMqxBKJMcaYCrFEYowxpkIskRhjjKkQSyTGGGMqxN/TAVSFpk2bakREhKfDMMaYGmXNmjX7VLVZee18IpFEREQQFxfn6TCMMaZGEZEtZ9LOhraMMcZUiCUSY4wxFWKJxBhjTIX4xBxJWQoLC8nMzCQvL8/TofiEoKAgwsLCCAgI8HQoxphK5rOJJDMzkwYNGhAREYGIeDocr6aqZGVlkZmZSWRkpKfDMcZUMp8d2srLyyMkJMSSSBUQEUJCQqz3Z4yX8tlEAlgSqUL2tTbGe/l0IjHGGG+1ftchnlycSlUsp26JxIP8/Pzo1asX3bp14/LLL+fAgQMAZGRkICLMmjXreNt9+/YREBDAtGnTAFi/fj0XXnghvXr1okuXLkydOhWAr776iuDgYHr16nX8z/Lly3/xuW+++ebxY4GBgXTv3p1evXoxY8aMM45927ZtTJw4saJfAmNMJSsoKuH55RsY89IK5q7exs6cKhhSVlWv/9O3b189WXJy8q/2VbV69eodf/2HP/xBH3nkEVVV3bx5s7Zr10579ep1/Pjf//537dmzp956662qqjpy5Ej96KOPjh+Pj49XVdUvv/xSL7vssjOOoW3btrp3794yjxUWFp75xZyB6vA1N8ab/bx1v4589mttO/0Tvf1/P+m+Q3kVOh8Qp2fwM9Z6JNXEoEGD2L59+/HtOnXq0KVLl+OlXd577z1++9vfHj++c+dOwsLCjm937969UuK4//77uemmmxgxYgTXXXcdmzZtYujQofTu3Zu+ffuyatUqANLS0ujVqxcAr732GhMmTGDUqFFERUUxc+bMSonFGHNmcguKeeSTZK76+3fk5Bby+pQYXpjUm5D6tavk83329t/SHvw4ieQdByv1nNGtG/LA5V3PqG1xcTGff/45N9xwwy/2T5o0iblz59KyZUv8/Pxo3bo1O3bsAODOO+9k2LBhDB48mJEjR3LdddfRqFEjAFasWHH8hzzA/Pnzad++/RnH/vPPP/PNN98QFBTE0aNHWbZsGUFBQaSmpjJlypTjyaS0devW8dNPP+Hv70/Hjh257bbbaN269Rl/pjHm3Hy/aR8z5iewNfsoVw8IZ8YlnWkYVLXPa1ki8aDc3Fx69epFRkYGffv2ZcSIEb84Pnr0aGbNmkWLFi1+NR9x3XXXMWrUKBYvXszChQv517/+xbp16wAYOnQon3zyyTnHNW7cOIKCggDIz89n2rRprFu3Dn9/fzZt2lTme4YPH06DBg0A6Ny5M1u3brVEYowbHcwr5G+LUvjfj9toG1KX/904kEHtQzwSiyUSOOOeQ2WrU6cOa9euJScnhzFjxjBnzhxuv/3248cDAwPp27cvzzzzDElJSXz88ce/eH/r1q25/vrruf766+nWrRuJiYmn/Kw5c+bw6quvArBo0aLT/pCvV6/e8dfPPPMMbdq04T//+Q+FhYXUr1+/zPfUrn2iC+3n50dRUdHpL94Yc86WJ+/mvo8S2Hson5vOb8cdwztSJ9DPY/G4dY5EREaLyHoRSRORX90SJCK1ReQ91/FVIhLh2h8iIl+KyGEReblU+7oi8qmIpIpIkog87s74q0pwcDAvvvgiTz/9NIWFhb849pe//IUnnniCkJBf/qaxePHi42137dpFVlYWoaGhp/yMW2+9lbVr17J27dqz6ink5OTQqlUrRIS33nqrSm4lNMaULetwPrf972f++HYcjesG8tGtQ5h5aRePJhFwYyIRET9gDnAJEA1MFpHok5rdAOxX1Q7Ac8ATrv15wCzgrjJO/bSqdgZ6A0NE5BJ3xF/VevfuTc+ePZk7d+4v9nft2pUpU6b8qv3SpUvp1q0bPXv2ZNSoUTz11FO0bNkSODFHcuzPvHnzzjmuadOm8dprrzFw4EC2bNnyi56HMaZqqCoL125n+LNfszhxJ/83oiOx086jR1gjT4cGgLjrN0wRGQTMVtVRru2ZAKr6t1JtlrjarBQRf2AX0Mx12xkici0Qo6rTTvEZLwCJqvrq6WKJiYnRkxe2SklJoUuXLud6eeYc2NfcmLO340Au93+UyBepe+gd3ognx/cgqkWDKvlsEVmjqjHltXPnHEkosK3UdiYw4FRtVLVIRHKAEGBfeScXkUbA5cALpzg+FZgKEB4efraxG2OMR5WUKP/9cSuPf5ZKcYny1zHRTBkcgV+t6lduyJ2JpKyrPbn7cyZtfn1ip/fyP+BFVU0vq42qvgK8Ak6PpLxzGmNMdbF53xGmz4/nx83ZnNehKX+7qjttmtT1dFin5M5Ekgm0KbUdBuw4RZtMV3IIBrLP4NyvABtV9fnKCNQYY6qDouISXv92M88u20Cgfy2eHN+D38SEVfuip+5MJKuBKBGJBLYDk4CrT2oTC0wBVgITgC+0nEkbEXkEJ+H8sdIjNsYYD0necZDp8+NJ2J7DyOgWPHxFN1o0DPJ0WGfEbYnENecxDVgC+AFvqGqSiDyEU78lFngdeEdE0nB6IpOOvV9EMoCGQKCIXAGMBA4C9wGpwE+uLP2yqr7mruswxhh3yi8q5uUv0vjHV5toVDeAOVf34dLuLat9L6Q0tz6QqKqLgEUn7ftrqdd5wG9O8d6IU5y25nx1jTHmNNZs2c/0+fGk7TnMVX1CmXVZNI3rBXo6rLNmT7YbY0wVO1pQxFNL1vPv7zNo1TCIN6/rx0Wdmns6rHNm1X89yFPrkRyzbds2IiMjyc527m/Yv38/kZGRbNmyhcjISNavX/+L9nfccQdPPvnkKa8nIyODbt26nfsXxBgf8O3GfYx87hve/C6Dawa2Zen/XVCjkwhYIvGoY7W2EhMTadKkCXPmzDl+rF27dr8ovPjBBx/QteuJmmC33347d955J2vXriUlJYXbbrvt+LGhQ4ceL4eydu1ahg8fXubnt2nThptvvvn4glYzZsxg6tSptG3b9njl4WNKSkqYN2+eLWZlzDnKyS3knnnr+P3rqwjwq8X7Nw3ioXHdqF+75g8M1fwrqAyfzYBdCZV7zpbd4ZIzLwU2aNAg4uPjj2+XXo8kJibm+Hokx8rIV9Z6JHfeeSd9+/bl+eef59tvv+Wll14CYPLkyUycOJEHHngAgG+++YaIiAjatm1LRkYG11xzDUeOHAHg5ZdfZvDgwef0+cb4giVJu5j1USJZRwq4+cL2/PniKIICPFsfqzJZIqkGPLkeSUBAAE899RSjR49m6dKlBAY6E309evSgVq1arFu37ngNsMmTJwPQvHnz42uUbNy4kcmTJ3NyCRpjDOw9lM/s2CQ+TdhJdKuGvHFtP7qFBns6rEpniQTOqudQmarLeiSfffYZrVq1IjEx8RcxTJ48mblz59K1a1cWLlzIQw89BEBhYSHTpk1j7dq1+Pn5sWHDhnP9EhjjlVSVD3/ezkOfJHM0v5i7R3Vi6vntCPDzztkE77yqGuLYHMmWLVsoKCj4xRwJ/HI9kvHjx//q/cfWI1m4cCH+/v6nXY/kVNauXcuyZcv44YcfeO6559i5c+fxY5MnT+b9999n+fLl9OjRg+bNnQnB5557jhYtWrBu3Tri4uIoKCg46881xlttP5DLtW+u5v/eX0f7ZvVZ9OfzuPWiDl6bRMASSbVQFeuRlEVVufnmm3n++ecJDw/n7rvv5q67TlTub9++PSEhIcyYMeP4sBacWKOkVq1avPPOOxQXF5/tJRvjdUpKlLdXZjDy2a9ZnZHN7Muj+eCmQXRoXjWVej3JEkk14Yn1SF599VXCw8OPD2fdcsstpKam8vXXXx9vM3nyZFJTU7nyyiuP77vlllt46623GDhwIBs2bPjFiorG+KJNew8z8ZWV/HVhEn3aNmbJHedz7ZBIalXDSr3u4Lb1SKoTW4+kerCvufE2hcUlvLoineeXb6ROgB+zxkQzvk9ojSpvcjrVYT0SY4zxWonbc5g+P56kHQe5pFtLHhzXleYNakaRxcpmicQHZGVlcfHFF/9q/+eff/6ruRdjzOnlFRbz0hcb+efX6TSuG8g/fteHS7q38nRYHuXTiURVvaYLejohISGsXbvWozH4whCq8X5rtmRzz7x4Nu09woS+Ydx/WRca1a15RRYrm88mkqCgILKysggJCfGJZOJJqkpWVhZBQb7Z7Tc135F8p8jiWyszaB1ch7ev78/5HZt5Oqxqw2cTSVhYGJmZmezdu9fTofiEoKCgX5R0Maam+HrDXu5dkMCOnFymDIrg7lGdqOcF9bEqk89+NQICAoiMjPR0GMaYaurA0QIe/iSF+T9l0r5ZPT64aRAxEU08HVa15LOJxBhjyqKqfJa4i78uTOTA0UKmXdSBacM6eFWRxcpmicQYY1z2HMxj1sJEliTtpltoQ966vj9dW3tfkcXKZonEGOPzVJUP1mTyyCfJ5BWVMH10Z24cGom/F9fHqkyWSIwxPm1b9lFmLkjg27R99I9owuPju9OuWX1Ph1WjWCIxxvikYleRxScXr6eWwMNXdON3/cN9pj5WZbJEYozxOWl7DnHPvHh+2nqACzs149EruxPaqI6nw6qx3DoAKCKjRWS9iKSJyIwyjtcWkfdcx1eJSIRrf4iIfCkih0Xk5ZPe01dEElzveVHsaUJjzBkqLC7h5S82cukL35K+7wjP/rYnb17bz5JIBbmtRyIifsAcYASQCawWkVhVTS7V7AZgv6p2EJFJwBPARCAPmAV0c/0p7R/AVOAHYBEwGvjMXddhjPEOCZk53D1vHam7DnFZj1Y8OLYrTevX9nRYXsGdQ1v9gTRVTQcQkbnAOKB0IhkHzHa9nge8LCKiqkeAb0WkQ+kTikgroKGqrnRtvw1cgSUSY8wp5BUW8/zyjby6Ip2QeoH865q+jOra0tNheRV3JpJQYFup7UxgwKnaqGqRiOQAIcC+05wz86Rznt2ygMYYn7EqPYsZCxLYvO8IE2PacO9lXQiuE+DpsLyOOxNJWXMXJ5eAPZM259ReRKbiDIERHh5+mlMaY7zNobxCnlicyn9+2EqbJnX4zw0DOC+qqafD8lruTCSZQJtS22HAjlO0yRQRfyAYyC7nnKUr/5V1TgBU9RXgFXBWSDyryI0xNdaXqXu478MEdh7M44bzIvnLyI7UDbQbVN3JnV/d1UCUiEQC24FJwNUntYkFpgArgQnAF3qahStUdaeIHBKRgcAq4A/AS+4I3hhTs2QfKeDhT5L58OftRDWvz/ybB9MnvLGnw/IJbkskrjmPacASwA94Q1WTROQhIE5VY4HXgXdEJA2nJzLp2PtFJANoCASKyBXASNcdXzcD/wbq4Eyy20S7MT5MVfkkfiezY5PIyS3kzxdHcctF7antb0UWq4r4wsp1MTExGhcX5+kwjDGVbPfBPO77MJHlKbvpERbMkxN60LllQ0+H5TVEZI2qxpTXzgYOjTE1jqry3uptPLoohYKiEu67tAvXDYmwIoseYonEGFOjbM06yowF8Xy/KYsBkU14YnwPIprW83RYPs0SiTGmRiguUd78bjNPL12Pf61aPHZldyb1a2NFFqsBSyTGmGpvw26nyOLabQcY1rk5j17ZjVbBVh+rurBEYoyptgqKSvjHV5t4+cuNNAgK4IVJvRjbszVWq7V6sURijKmW1m07wPT58aTuOsTYnq154PJoQqzIYrVkicQYU63kFhTz3PINvLYineYNgnjtDzEMj27h6bDMaVgiMcZUGys3ZTFjQTxbso4yuX84My/tTMMgK7JY3VkiMcZ43MG8Qv62KJX//biVtiF1+e+NAxjc3oos1hSWSIwxHrU8eTf3f5TInkN5TD2/HXcO70idQCtvUpNYIjHGeETW4Xwe/DiZ2HU76NyyAf+6pi892zTydFjmHFgiMcZUKVUldt0OZscmcTi/iDuGR3HLhR0I9LfyJjWVJRJjTJXZmZPL/R8m8nnqHnq1acSTE3rQsUUDT4dlKsgSiTHG7UpKlP+t3srfFqVSVFLC/Zd14bohkfhZeROvYInEGONWGfuOMGNBPD+kZzO4fQiPX9WD8JC6ng7LVCJLJMYYtygqLuGN7zbzzNINBPrV4vGrujOxXxsrb+KFLJEYYypdys6DTJ8fT3xmDsO7tOCRK7rRMjjI02EZN7FEYoypNPlFxcz5chN//zKN4DoBvHx1by7r3sp6IV7OEokxplL8vHU/0+fHs2H3Ya7sHcpfx0TTuF6gp8MyVcASiTGmQo4WFPHM0g288d1mWjUM4s1r+3FR5+aeDstUIUskxphz9l3aPmYsiGdbdi7XDGzLPaM70cCKLPocSyTGmLOWk1vIY5+m8F7cNiKb1uO9qQMZ0C7E02EZD7FEYow5K0uSdjHro0SyjhTwpwvac8fwKIICrMiiL3NrcRsRGS0i60UkTURmlHG8toi85zq+SkQiSh2b6dq/XkRGldp/p4gkiUiiiPxPROyeQmOqwN5D+dz67k/c9M4aQurX5qNbhjDjks6WRIz7eiQi4gfMAUYAmcBqEYlV1eRSzW4A9qtqBxGZBDwBTBSRaGAS0BVoDSwXkY5AS+B2IFpVc0XkfVe7f7vrOozxdarKhz9v56FPkjmaX8zdozox9fx2BPhZkUXjcOfQVn8gTVXTAURkLjAOKJ1IxgGzXa/nAS+Lc8P5OGCuquYDm0UkzXW+ra6Y64hIIVAX2OHGazDGp20/kMt9Hybw1fq99Al3iix2aG5FFs0vuTORhALbSm1nAgNO1UZVi0QkBwhx7f/hpPeGqupKEXkaJ6HkAktVdWlZHy4iU4GpAOHh4RW/GmN8SEmJ8u6qLTz+WSoKzL48mmsGRViRRVMmdyaSsr7j9AzblLlfRBrj9FYigQPAByLye1X9z68aq74CvAIQExNz8ucaY04hfe9hZsxP4MeMbIZGNeWxK7vTpokVWTSn5s5Ekgm0KbUdxq+HoY61yRQRfyAYyD7Ne4cDm1V1L4CILAAGA79KJMaYs1NUXMKrKzbz3PINBPnX4qkJPZjQN8zKm5hyuTORrAaiRCQS2I4zKX71SW1igSnASmAC8IWqqojEAv8VkWdxJtujgB+BEmCgiNTFGdq6GIhz4zUY4xOSdxzknvnrSNx+kNFdW/LQFV1p3sBuiDRnxm2JxDXnMQ1YAvgBb6hqkog8BMSpaizwOvCOazI9GyfZ4Gr3Ps7EfBFwq6oWA6tEZB7wk2v/z7iGr4wxZy+/qJiXPk/jn19volHdQP7xuz5c0r2Vp8MyNYyoev/0QUxMjMbFWcfFmNLWbMnmnnnxbNp7hPF9wpg1pguN6lqRRXOCiKxR1Zjy2tmT7cb4mCP5RTy1ZD1vrcygdXAd3r6+P+d3bObpsEwNZonEGB/yzYa9zFyQwI6cXKYMiuDuUZ2oV9t+DJiKse8gY3zAgaMFPPJpCvPWZNKuWT0+uGkQMRFNPB2W8RKWSIzxcp8l7GTWwiT2Hy3glgvbc/vFVmTRVC5LJMZ4qT2H8nhgYRKfJe6ia+uGvHV9P7q2DvZ0WMYLWSIxxsuoKvPWZPLIpynkFhZzz+hO3DjUiiwa97FEYowX2ZZ9lHs/TGDFxn30i2jM4+N70L5ZfU+HZbycJRJjvEBJifL2ygyeXLIeAR4c25VrBrallhVZNFXAEokxNVzankNMn5/Ami37uaBjMx69shthja3Ioqk6p00kIjJMVb9wvY5U1c2ljl2lqgvcHaAxpmyFxSX86+tNvPh5GnVr+/Hsb3tyZe9QK7Joqlx5PZKngT6u1/NLvQa4H7BEYowHJG7P4e558aTsPMhlPVox+/KuNGtQ29NhGR9VXiKRU7wua9sY42Z5hcU8v3wjr65Ip0m9QP75+76M7tbS02EZH1deItFTvC5r2xjjRqvSs5ixIIHN+44wMaYN917aheC6AZ4Oy5hyE0k719ogUuo1ru1It0ZmjAHgUF4hTy5ezzs/bKFNkzr854YBnBfV1NNhGXNceYlkXKnXT5907ORtY0wl+3L9Hu5bkMDOg3lcPySSu0Z1pG6g3WxpqpfTfkeq6telt0UkAOgGbFfVPe4MzBhftv9IAQ9/ksyCn7fToXl95t88mD7hjT0dljFlKu/2338CL7lWLAzGWRK3GGgiInep6v+qIkhjfIWq8mnCTh5YmERObiG3D+vArcM6UNvfiiya6qu8PvJQVf2T6/V1wAZVvUJEWgKfAZZIjKkkuw/mMeujRJYm76Z7aDD/+eMAurRq6OmwjClXeYmkoNTrEcAHAKq6yx56MqZyqCofxGXy8KfJFBSVMPOSztxwXiT+VmTR1BDlJZIDIjIG2A4MAW4AEBF/oI6bYzPG623NOsrMD+P5Li2L/pFNeGJ8DyKb1vN0WMaclfISyU3Ai0BL4A5V3eXafzHwqTsDM8abFZco//4+g6eXrMevlvDold2Y3C/ciiyaypGdDsmxsO1HmPQuuHkEqby7tjYAo8vYvwRY4q6gjPFmG3Yf4p558azddoBhnZvz6JXdaBVsHXxTQXvXO8kjeSHsTnD2te4NR/ZB/WZu/ejy7tp68XTHVfX2ct4/GngB8ANeU9XHTzpeG3gb6AtkARNVNcN1bCbOUFoxcLsreSEijYDXcG5DVuB6VV15ujiMqQ4Kikr459ebeOmLjdSv7c8Lk3oxtmdrK7Jozo0q7EqAlFgngexb7+xvMwBGPgpdLofGbasklPKGtv4EJALvAzs4i/paIuIHzMGZpM8EVotIrKoml2p2A7BfVTuIyCTgCWCiiEQDk4CuQGtguYh0VNVinMS0WFUniEggYPWyTbW3btsBps+PJ3XXIS7v2ZrZl0cTUt+KLJqzpArb1zi9jpSPYf9mkFrQdgj0vxE6j4GGrao8rPISSSvgN8BEoAh4D5ivqvvP4Nz9gTRVTQcQkbk4T8qXTiTjgNmu1/OAl8X59WwcMFdV84HNIpIG9BeRJOB84FoAVS3gl3eWGVOt5BYU89zyDby2Ip3mDYJ47Q8xDI9u4emwTE1SUgzbVjm9jpSP4WAm1PKHyAvgvDuc5FHPsyVzypsjyQL+CfxTREKByUCSiExX1XfKOXcosK3UdiYw4FRtVLVIRHKAENf+H056byiQC+wF3hSRnsAa4M+qeqScWIypcis3ZTFzQTwZWUeZ3D+cmZd2pmGQFVk0Z6C4CDJWOMNWKZ/AkT3gVxs6XAzD7odOo6FO9al0cEZFe0SkD04SGYHzIOKaM3lbGftOrhh8qjan2u+PsybKbaq6SkReAGYAs8qIeSowFSA8PPwMwjWmchzKK+Rvn6Xy31VbaRtSl//eOIDB7a3IoilHUT6kfw0pCyF1EeRmQ0BdiBoJ0WOdv2s38HSUZSpvsv1BYAyQAswFZqpq0RmeOxNoU2o7DGeepaw2ma5nU4KB7NO8NxPIVNVVrv3zcBLJr6jqK8ArADExMVby3lSJL1J3c++CRPYcyuOP50Xyl5GdqBNo5U3MKRTmQtpyZ9hqw2LIPwi1G0LH0U7yaH8xBFb/aeDyeiSzgHSgp+vPY647TARQVe1xmveuBqJEJBLngcZJwNUntYkFpuDU8JoAfKGq6ipX/18ReRZnsj0K+FFVi0Vkm4h0UtX1OM+zJGOMh2UdzuehT5JZuHYHnVo04J/X9KVXm0aeDstUR/mHYMMSZ9hq4zIoPOoMU0WPhS7joN0F4F+zbsQoL5Gc85ojrjmPaTjPm/gBb7iKPz4ExKlqLPA68I5rMj0bJ9ngavc+TpIoAm513bEFcBvwruuOrXScGmDGeISq8nH8TmbHJnEor5A7hkdxy4UdCPS38iamlNz9sH6xkzzSPofifKjXHHpOguhx0PY88Ku5ywOI6tmP+rhu7Z2kqu9WfkiVLyYmRuPi4jwdhvEyu3LyuP+jBJan7KFnm0Y8Ob4HnVpWzzFs4wFH9kHqJ86w1eavoaQIGoZCl7FO76PNAKhVvYc9RWSNqsaU1668OZKGwK04d0zFAsuAacBdwFqgRiQSYyqTqjJ39TYe+zSFwpIS7r+sC9cNicTPypuYgztdyWMhbPkOtAQaR8DAW5yeR+s+UMv7eqvl9aXeAfbjzGH8EbgbCATGqepaN8dmTLWTse8IMxcksDI9i0HtQnh8fHfahliRRZ92YKvrGQ9XbSsUmnaCoX9xeh8tu7u91pWnlbtmu6p2BxCR14B9QLiqHnJ7ZMZUI8UlyhvfbuaZZesJqFWLx6/qzsR+bay8ia/K2uT0OpIXwk7X79QtusNF9zrJo3lnz8ZXxcpLJIXHXrjumNpsScT4mtRdB5k+L551mTkM79KcR67oTsvgIE+HZaqSKuxJOVHXak+Ssz+0Lwx/0JnzaNLOszF6UHmJpKeIHHS9FqCOa/vY7b+2fJvxWvlFxcz5chN//zKN4DoBvDS5N2N6tLJeiK9QdXobx4atstIAgfBBMPpxpyhicJino6wWyiuRUr1vKTDGTX7eup/p8+PZsPswV/YOZdaYaJrUC/R0WMbdSkpge5yrKGKsM/8hfhA51Jkw7zwGGlittJPV3BuXjXGDowVFPLN0A298t5mWDYN449oYhnW2HxxeraQYtnzvqmv1MRzaCbUCoP1FcP490PkyqNvE01FWa5ZIjHH5Pm0fMxYksDX7KL8fGM700Z1pYEUWvVNxIWz+xkkeqZ/Ckb3gHwQdhju36XYcBUHBno6yxrBEYnxeTm4hf1uUwtzV24gIqcvcqQMZ2C7E02GZylaYB+lfOnMe6xdB3gEIrH+iKGKHEVC7vqejrJEskRiftjRpF/d/lMi+w/ncdEE77hzekaAAmxr0GgVHnHpWKbFOfavXeE9PAAAbV0lEQVSCw05Po9Olzm267YdBgN2BV1GWSIxP2nson9kfJ/Fp/E46t2zAa1Ni6BFmRRa9Qt5BV1HEhbBxORTlQt0Q6Dbe6XlEnA/+duNEZbJEYnyKqvLR2u08+HEyR/OLuWtkR266oD0Bft5XtsKnHM12hquSY53hq+ICqN8Sev/eSR7hg2t0UcTqzr6yxmdsP5DLfR8m8NX6vfQJb8STE3rQobkVWayxDu85Uddq8wrQYghuA/2nOsNWYf28sq5VdWSJxHi9khLl3R+38viiFBSYfXk01wyKsCKLNVHOducW3ZRY55ZdFJq0hyG3O8mjdW+vr2tVHVkiMV4tfe9hZsxP4MeMbIZGNeWxK7vTpkn1X3HOlJK9+URpku2u5SCaR8MF051hq+bRljw8zBKJ8UpFxSW89u1mnlu2gdr+tXhqQg8m9A2z8iY1xd4NzmR58kLYleDsa9UThs1ynvNoGuXZ+MwvWCIxXid5x0Humb+OxO0HGdW1BQ+P60bzhnaLZ7WmCrsTT9S12pvq7A/rByMfcepaNY7waIjm1CyRGK+RX1TMy1+k8Y+vNtGobiD/+F0fLuneytNhmVNRhR0/nUge2ekgtZw7rC550qlrFRzq6SjNGbBEYrzCmi3ZTJ+fQNqew4zvE8asMV1oVNeeFah2Skpg26oTda1ytkEtf4g8Hwbf7iSP+s08HaU5S5ZITI12JL+Ip5as562VGbQOrsNb1/fngo72g6haKS6CLd86PY/UT+DwbvCr7TxVftG90HG0FUWs4SyRmBprxca9zFyQQOb+XKYMasvdoztTv7Z9S1cLRQWQ/pUzYZ66CHKzIaAuRI1wbtPtOApq2zM83sL+15kaJ+doIY98mswHazJp16weH/xpEP0i7DdajyvMhbTPnWGr9Z9B/kEIbACdRjvJo8NwCLRbr72RWxOJiIwGXgD8gNdU9fGTjtcG3gb6AlnARFXNcB2bCdwAFAO3q+qSUu/zA+KA7ao6xp3XYKqXxYk7mbUwiewjBdxyYXtuvzjKiix6Uv5h2LjEGbbauAwKj0BQI+cuq+hx0O5C8K/t6SiNm7ktkbh+2M8BRgCZwGoRiVXV5FLNbgD2q2oHEZkEPAFMFJFoYBLQFWgNLBeRjqpa7Hrfn4EUwJb69RF7DuXxwMIkPkvcRXSrhrx5bT+6hdp6ER6RewA2LHaSx6bPoSgP6jWDHr91FUUcCn62josvcWePpD+QpqrpACIyFxgHlE4k44DZrtfzgJfFeWJsHDBXVfOBzSKS5jrfShEJAy4DHgX+z43xm2pAVZm3JpNHPk0ht7CYu0d1Yur57azIYlU7kuVMlKfEQvrXUFIIDUOh77XOsFX4QKhlPUNf5c5EEgpsK7WdCQw4VRtVLRKRHCDEtf+Hk9577Iby54F7AJup83Lbso9y74cJrNi4j5i2jXl8fA86NLeFh6rMoV0n6lplfAtaAo3awsA/QZdxENrXiiIawL2JpKxaFHqGbcrcLyJjgD2qukZELjzth4tMBaYChIeHlx+tqTZKSpR3ftjCE4udp5sfHNuVawa2pZYVWXS/A9tO1LXatgpQaNoRzvs/Z9iqZQ+ra2V+xZ2JJBNoU2o7DNhxijaZIuIPBAPZp3nvWGCsiFwKBAENReQ/qvr7kz9cVV8BXgGIiYk5OYGZamrT3sNMnxdP3Jb9nN+xGY9d2Y2wxnanj1tlbTqRPHb85Oxr0d15xqPLWGje2bPxmWrPnYlkNRAlIpHAdpzJ86tPahMLTAFWAhOAL1RVRSQW+K+IPIsz2R4F/KiqK4GZAK4eyV1lJRFT8xQWl/DKN+m88PlG6gT48cxvenJVn1ArsugOqk4tq2OlSXYnOvtb94Hhs53kEdLekxGaGsZticQ15zENWIJz++8bqpokIg8BcaoaC7wOvOOaTM/GSTa42r2PMzFfBNxa6o4t42USt+cwfX48STsOcmn3lswe25XmDazIYqVShV3xTvJIXghZGwGBNgNg1GPO7bqNbAjYnBtR9f5Rn5iYGI2Li/N0GOYkeYXFvPj5Rv71TTpN6gXy8LiujO5mRRYrTUkJbF/jKsceCwe2gPhBxBCn19HlcmjQ0tNRmmpMRNaoakx57ezJduMRcRnZ3DM/nvS9R/hN3zDuvyya4Lr27EGFlRTD1pWuYauP4dAOqBXgPBh4/l3Q6TKoF+LpKI2XsURiqtTh/CKeXJzK2yu3ENa4Du/c0J+hUVZksUKKCyFjxYmiiEf2OkUROwyH6Aecooh1Gnk6SuPFLJGYKvPV+j3c92EiO3JyuXZwBHeP6kQ9K7J4borynaKIyQth/SLI3Q8B9aDjSGfYKmqEFUU0Vcb+Fxu323+kgIc/TWbBT9tp36we8/40iL5trcjiWSs4CmnLXUURF0PBIagd7BRFjB7nlGUPqOPpKI0PskRi3EZVWZSwiwdiEzlwtJDbhnVg2rAO1Pa3UhpnLO8gbFzq9DzSlkPhUajTBLpe4SSPyAvA3xbwMp5licS4xZ6Dedz/USJLk3fTPTSYt68fQHRrq7F5Ro5mO2XYU2Jh0xdQXAD1W0Kvq51hq7ZDwM/+65rqw74bTaVSVT6Iy+ThT5MpKCph5iWdueG8SPytyOLpHd4LqR87E+YZK6CkCILbQL8bndIkYf2trpWptiyRmEqzLfsoMxck8G3aPvpHNuHxq7rTrpkVWTylgzucW3STY2Hr905RxCbtYNA0J3m07mN1rUyNYInEVFhxifLW9xk8tWQ9frWER67oxtX9w63IYln2b3HVtVoImaudfc06w9C7nOTRopslD1PjWCIxFbJx9yGmz4/np60HuKhTMx69sjutG9mdQ7+wb6OTOFJiYec6Z1/LHjDsfqcce7OOno3PmAqyRGLOSWFxCf/8ahMvfZFGvdp+PDexJ1f0siKLgFPXanfSiYq6e1Oc/WH9YMTDTmmSJpGejdGYSmSJxJy1hMwc7p63jtRdh7i8Z2seuDyapvV9fF1uVdjx84lhq+x0kFoQPhgueRI6j4Hg0PLPY0wNZInEnLG8wmKeW76BV79Jp1mD2rz6hxhGRLfwdFieU1LizHMkL3QmzXO2OkURI8+Hwbc5yaN+c09HaYzbWSIxZ+SH9CxmzI8nI+sok/u3YcYlXQiu44NFFouLnDusjtW1OrQT/AKh3UVw4QzodAnUtaf2jW+xRGJO61BeIY9/lsq7q7YS3qQu7/5xAEM6NPV0WFWrqAA2f+OUY0/9FI5mgX8diBruTJZ3HAVB9rCl8V2WSMwpfZG6m/s+TGT3wTz+eF4k/zeyI3UDfeRbpjDXeao8ORY2fAZ5ORDYwEka0WOdyrqB9TwdpTHVgo/8VDBnI/tIAQ99nMRHa3fQsUV9/v67wfQOb+zpsNwv/zCkLXPmPDYshcIjENTIWcMjeqwzfBVgKzcaczJLJOY4VeXj+J3Mjk3iUF4hdwyP4pYLOxDo78WlOfJynEq6KbFOUcSiPKjbFHr8xqlrFXk++PngXJAxZ8ESiQFgV45TZHF5ym56hgXzxIQBdG7ppeP+R7OduY6UWNj0JZQUQoNW0OcPrqKIg6GWVSg25kxZIvFxqsrc1dt47NMUCktKuP+yLlw3JBI/bytvcmh3qaKI34IWQ6NwGHCTU449NMaKIhpzjiyR+LAtWUeYMT+BlelZDGoXwuPju9M2xIsmkA9sc57vSImFrT8ACiFRcN4dTs+jVU+ra2VMJbBE4oOKS5Q3v9vM00vXE1CrFn+7qjuT+rXxjvIm2elOryN5Iez4ydnXvKvzjEf0OKdAojdcpzHViCUSH7N+1yHumR/Pum0HuLhzcx65shutgmt4kcW9608kj90Jzr7WveHiB5zkEdLes/EZ4+XcmkhEZDTwAuAHvKaqj590vDbwNtAXyAImqmqG69hM4AagGLhdVZeISBtX+5ZACfCKqr7gzmvwFgVFJcz5Mo2/f5VGg6AAXpzcm8t7tKqZvRBV2JVwoijivvXO/jYDYNRjTlHERuGejdEYH+K2RCIifsAcYASQCawWkVhVTS7V7AZgv6p2EJFJwBPARBGJBiYBXYHWwHIR6QgUAX9R1Z9EpAGwRkSWnXROc5K12w5wz7x1bNh9mCt6teavl3elSb0ats63Kmxfc6Ic+/4Mpyhi2yHQ/0anrlXDVp6O0hif5M4eSX8gTVXTAURkLjAOKP1Dfxww2/V6HvCyOL8ijwPmqmo+sFlE0oD+qroS2AmgqodEJAUIPemcxiW3oJhnlq7nje8206JhEG9cG8OwzjWoyGJJsTNJnhLrTJof3A61AqDdBXDe/0Hny6Cej5VrMaYacmciCQW2ldrOBAacqo2qFolIDhDi2v/DSe/9RQ1uEYkAegOrKjNob/F92j5mLEhga/ZRfjcgnBmXdKZBUA14sK640Lk9NyUWUj6BI3vArzZ0uBiGzYJOo6GODzxlb0wN4s5EUtbgu55hm9O+V0TqA/OBO1T1YJkfLjIVmAoQHu474+U5uYX8bVEKc1dvIyKkLnOnDmRguxBPh3V6RfmQ/pUz37H+U8jdDwH1IGqEU5okaiTUbuDpKI0xp+DORJIJtCm1HQbsOEWbTBHxB4KB7NO9V0QCcJLIu6q64FQfrqqvAK8AxMTEnJzAvNKy5N3c/1ECew/lc9MF7bhzeEeCAqrpE9qFuU5JkuRY2LAY8g9C7YZOGfYuY50eSEANv5vMGB/hzkSyGogSkUhgO87k+dUntYkFpgArgQnAF6qqIhIL/FdEnsWZbI8CfnTNn7wOpKjqs26MvUbZdzifBz9O5uN1O+jcsgGv/iGGHmGNPB3Wr+Ufgg1LnGGrjcug8CjUaeL0OrqMc+Y+/H18pUVjaiC3JRLXnMc0YAnO7b9vqGqSiDwExKlqLE5SeMc1mZ6Nk2xwtXsfZxK9CLhVVYtF5DzgGiBBRNa6PupeVV3kruuozlSVhWt38ODHSRzOL+LO4R25+cL21avIYu7+UkURP4fifKjXHHpOcnoeEUPBzx5nMqYmE1XvH/WJiYnRuLg4T4dRqXYcyOX+jxL5InUPvcMb8eT4HkS1qCbzCEf2OasHJsfC5q+hpAgahjnPd0SPdZ73sKKIxlR7IrJGVWPKa2e/CtYwJSXKf3/cyuOfpVJcovx1TDRTBkd4vsjiwZ0n6lpt+Q60BBpHwqBbnWGr0D5WmsQYL2WJpAbZvO8I0+fH8+PmbM7r0JS/XdWdNk3qei6g/Vuc5JG8EDJ/dPY17QRD/+KUJmnRzZKHMT7AEkkNUFRcwmvfbua5ZRsI9K/FE+O789sYDxVZ3JfmrF2eHAs7XdNULbrDRfe5iiJ2qvqYjDEeZYmkmkvecZDp8+NJ2J7DyOgWPHxFN1o0rMLlXlVhT8qJulZ7kpz9oX1h+IPOnEeTdlUXjzGm2rFEUk3lFxXz8hdp/OOrTTSqG8Dff9eHS7q1rJpeiKrT20iOdRJIVhogED4IRj/uTJoHh7k/DmNMjWCJpBpas2U/0+fHk7bnMFf1CWXWZdE0dneRxZIS2B53oijiga0gfhA5FAbe4hRFbFCD6nQZY6qMJZJq5Eh+EU8vXc+/v8+gdXAd/n1dPy7s1Nx9H1hSDFu+P1EU8dBOpyhi+4vg/Hucooh1m7jv840xXsESSTWxYuNeZi5IIHN/LlMGteXu0Z2pX9sN/zzFhbD5mxNFEY/uA/8g6DDcmSzvOAqCgiv/c40xXssSiYflHC3k0UXJvB+XSbtm9fjgT4PoF1HJvYDCPEj/0lUUcRHkHYDA+k4xxOix0GEE1K5fuZ9pjPEZlkg8aEnSLmZ9lEjWkQJuubA9t18cVXlFFguOOPWsUmJhw1IoOOT0NDpd6pQmaT8MAqrw7i9jjNeyROIBew/lMzs2iU8TdhLdqiFvXNuPbqGVMJyUl+MURUxe6NS1KsqFuiHQ7Upn2CrifPCvYSsjGmOqPUskVUhVWfDTdh76JJncwmLuHtWJqee3I8CvAkUWj2Y7w1XJsc7wVXEB1G8JvX/vDFuFD7aiiMYYt7KfMFVk+4Fc7l2QwNcb9tK3bWOeGN+DDs3PcV7i8J4Tda02rwAthuBw6Hej0/MI6we1qlEFYGOMV7NE4mYlJcp/Vm3hic9SUeDBsV25ZmBbap1tkcWc7aWKIn4PKDRpD0Nud+Y8Wve2ulbGGI+wROJGm/YeZsb8eFZn7GdoVFMeu/Isiyxmbz5RmmS7qwx+82i4YLozbNU82pKHMcbjLJG4QWFxCa+uSOf55RupE+DH07/pyfg+oWdW3mTveldpkoWwK8HZ16oXXPxXpxx70w7uDd4YY86SJZJKlrg9h+nz40nacZBLu7dk9tiuNG9wmttsVZ2EcaznsW+9sz+sP4x8xKlr1TiiSmI3xphzYYmkkuQVFvPi5xv51zfpNK4byD9/34fR3VqV3VgVtv90ohz7/s0gtaDtEOj3R+gyBhq2rtoLMMaYc2SJpBLEZWRzz/x40vceYULfMGZdFk1w3YBfNiopgW2rXEURP4aDmVDLHyLPhyF/dooi1m/mmQswxpgKsERSAYfzi3hqcSpv/7CF1sF1ePv6/pzfsVQyKC6CLd86vY7UT+DwbvCr7TxVPuw+6DjaiiIaY2o8SyTn6OsNe7l3QQI7cnKZMiiCu0d1ol5tfygqgPSvnGGr1EWQmw0BdU8URYwaCUENPR2+McZUGkskZ+nA0QIe/iSF+T9l0r5ZPeb9aRB9W9eBtMXOhPn6xZCfA4ENoNNo5xmPDsMh0INrqxtjjBu5NZGIyGjgBcAPeE1VHz/peG3gbaAvkAVMVNUM17GZwA1AMXC7qi45k3O606KEnfx1YSIHjhZyx/mtuCU0ncBVdzrFEQuPQJ3Gzl1W0WOh3YXgX7uqQjPGGI9xWyIRET9gDjACyARWi0isqiaXanYDsF9VO4jIJOAJYKKIRAOTgK5Aa2C5iHR0vae8c1a6PQfz+OvCJL5P2sSUpincGJpIw5++gR/zoF4z6PFbV1HE88AvoPwTGmOMF3Fnj6Q/kKaq6QAiMhcYB5T+oT8OmO16PQ94WZyn9sYBc1U1H9gsImmu83EG56w0qkrs9/H8vOxdri75gTl1kvA7XATSGvpMcZJH+ECoVUml340xpgZyZyIJBbaV2s4EBpyqjaoWiUgOEOLa/8NJ7w11vS7vnJWisKiYxKcvYUzuj4wTpbBROH7dbnaeLg/ta0URjTHGxZ2JpKx6IHqGbU61v6yf3ief0zmxyFRgKkB4ePipozyFAH8/CoMjSW7dna4XX0NA655W18oYY8rgzkSSCbQptR0G7DhFm0wR8QeCgexy3lveOQFQ1VeAVwBiYmLKTDbl6X/zv87lbcYY41PcOT6zGogSkUgRCcSZPI89qU0sMMX1egLwhaqqa/8kEaktIpFAFPDjGZ7TGGNMFXJbj8Q15zENWIJzq+4bqpokIg8BcaoaC7wOvOOaTM/GSQy42r2PM4leBNyqqsUAZZ3TXddgjDGmfOJ0ALxbTEyMxsXFeToMY4ypUURkjarGlNfObj0yxhhTIZZIjDHGVIglEmOMMRViicQYY0yFWCIxxhhTIT5x15aI7AW2nOPbmwL7KjGcmsCu2Tf42jX72vVCxa+5raqWu3SrTySSihCRuDO5/c2b2DX7Bl+7Zl+7Xqi6a7ahLWOMMRViicQYY0yFWCIp3yueDsAD7Jp9g69ds69dL1TRNdsciTHGmAqxHokxxpgKsURyCiIyWkTWi0iaiMzwdDzuIiJviMgeEUksta+JiCwTkY2uvxt7MsbKJCJtRORLEUkRkSQR+bNrvzdfc5CI/Cgi61zX/KBrf6SIrHJd83uupRm8ioj4icjPIvKJa9urr1lEMkQkQUTWikica5/bv7ctkZRBRPyAOcAlQDQwWUSiPRuV2/wbGH3SvhnA56oaBXzu2vYWRcBfVLULMBC41fVv683XnA8MU9WeQC9gtIgMBJ4AnnNd837gBg/G6C5/BlJKbfvCNV+kqr1K3fbr9u9tSyRl6w+kqWq6qhYAc4FxHo7JLVT1G5y1YEobB7zlev0WcEWVBuVGqrpTVX9yvT6E80MmFO++ZlXVw67NANcfBYYB81z7veqaAUQkDLgMeM21LXj5NZ+C27+3LZGULRTYVmo707XPV7RQ1Z3g/OAFmns4HrcQkQigN7AKL79m1xDPWmAPsAzYBBxQ1SJXE2/8Hn8euAcocW2H4P3XrMBSEVkjIlNd+9z+ve3ONdtrMiljn93e5kVEpD4wH7hDVQ86v6x6L9cKo71EpBHwIdClrGZVG5X7iMgYYI+qrhGRC4/tLqOp11yzyxBV3SEizYFlIpJaFR9qPZKyZQJtSm2HATs8FIsn7BaRVgCuv/d4OJ5KJSIBOEnkXVVd4Nrt1dd8jKoeAL7CmR9qJCLHfpn0tu/xIcBYEcnAGZoehtND8eZrRlV3uP7eg/MLQ3+q4HvbEknZVgNRrjs8AnHWko/1cExVKRaY4no9BVjowVgqlWuc/HUgRVWfLXXIm6+5masngojUAYbjzA19CUxwNfOqa1bVmaoapqoROP9/v1DV3+HF1ywi9USkwbHXwEggkSr43rYHEk9BRC7F+Q3GD3hDVR/1cEhuISL/Ay7EqRK6G3gA+Ah4HwgHtgK/UdWTJ+RrJBE5D1gBJHBi7PxenHkSb73mHjiTrH44vzy+r6oPiUg7nN/WmwA/A79X1XzPReoerqGtu1R1jDdfs+vaPnRt+gP/VdVHRSQEN39vWyIxxhhTITa0ZYwxpkIskRhjjKkQSyTGGGMqxBKJMcaYCrFEYowxpkIskRhTiUTkShFREens2o4oXVn5FO8pt40x1ZklEmMq12TgW5yH4IzxCZZIjKkkrvpdQ3BKk/8qkYjItSKyUEQWu9a6eaDUYT8RedW1XshS1xPoiMiNIrLatZbIfBGpWzVXY8yZs0RiTOW5AlisqhuAbBHpU0ab/sDvcNYF+Y2IHFszIgqYo6pdgQPAeNf+Baraz7WWSAreuX6GqeEskRhTeSbjlN/A9ffkMtosU9UsVc0FFgDnufZvVtW1rtdrgAjX624iskJEEnASUFe3RG5MBVgZeWMqgaue0TCcH/yKU9dKgb+f1PTkmkTHtkvXeyoG6rhe/xu4QlXXici1OHXRjKlWrEdiTOWYALytqm1VNUJV2wCbcUqVlzbCtYZ2HZyhsO/KOW8DYKer9P3vKj1qYyqBJRJjKsdkTlRePWY+TmXh0r4F3gHWAvNVNa6c887CqUy8DKiSRYqMOVtW/deYKuIamopR1WmejsWYymQ9EmOMMRViPRJjjDEVYj0SY4wxFWKJxBhjTIVYIjHGGFMhlkiMMcZUiCUSY4wxFWKJxBhjTIX8PwzmfMgxJZ+DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Lassoparameter(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train data aside 1204.9955481680481\n",
      "RMSE on test data aside 1267.4121534852347\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train,y_train)\n",
    "p = lasso.predict(X_train)\n",
    "err = p-y_train\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "p = lasso.predict(X_test)\n",
    "err = p-y_test\n",
    "total_error = np.dot(err,err)\n",
    "rmse_test = np.sqrt(total_error/len(p))\n",
    "print (\"RMSE on train data aside {}\".format(rmse_train))\n",
    "print (\"RMSE on test data aside {}\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
